
        {
            "cells": [
          {
           "cell_type": "code",
           "metadata": {},
            "execution_count": null, "outputs": [], 
           "source": ["#r \"nuget: FSharp.Control.AsyncSeq,{{package-version}}\"\n"]
          }
,
          {
           "cell_type": "markdown",
           "metadata": {},
           
           "source": ["[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/fsprojects/FSharp.Control.AsyncSeq/gh-pages?filepath=AsyncSeqExamples.ipynb)\n",
"\n",
"# F# AsyncSeq Examples\n",
"\n",
"\n"]
          }
,
          {
           "cell_type": "code",
           "metadata": {},
            "execution_count": null, "outputs": [], 
           "source": ["#r \"../../../bin/FSharp.Control.AsyncSeq.dll\"\n",
"open System\n",
"open FSharp.Control\n"]
          }
,
          {
           "cell_type": "markdown",
           "metadata": {},
           
           "source": ["## Group By\n",
"\n",
"`AsyncSeq.groupBy` partitions an input sequence into sub-sequences with respect to the specified `projection` function. This operation is the asynchronous analog to `Seq.groupBy`.\n",
"\n",
"### Example Execution\n",
"\n",
"An example execution can be depicted visually as follows:\n",
"\n",
"```\n",
"--------------------------------------------------\n",
"| source  | a0 | a2 | a3 | a4 | a5 |             |\n",
"| key     | k1 | k2 | k1 | k3 |    |             | \n",
"| result  | k1 * [a1,a3] | k2 * [a2] | k3 * [a4] |\n",
"--------------------------------------------------\n",
"```\n",
"\n",
"### Use Case\n",
"\n",
"Suppose we would like to consume a stream of events `AsyncSeq\u003cEvent\u003e` and perform an operation on each event. The operation on each event is of type `Event -\u003e Async\u003cunit\u003e`. This can be done as follows:\n",
"\n",
"\n"]
          }
,
          {
           "cell_type": "code",
           "metadata": {},
            "execution_count": null, "outputs": [], 
           "source": ["type Event = {\n",
"  entityId : int64\n",
"  data : string \n",
"}\n",
"\n",
"let stream : AsyncSeq\u003cEvent\u003e =\n",
"  failwith \"undefined\"\n",
"\n",
"let action (e:Event) : Async\u003cunit\u003e =\n",
"  failwith \"undefined\"\n",
"\n",
"stream \n",
"|\u003e AsyncSeq.iterAsync action\n"]
          }
,
          {
           "cell_type": "markdown",
           "metadata": {},
           
           "source": ["The above workflow will read an event from the stream, perform an operation and then read the next event.\n",
"While the read operation and the operation on the event are *asynchronous*, the stream is processed *sequentially*.\n",
"It may be desirable to parallelize the processing of the stream. Suppose that events correspond to some entity, \n",
"such as a shopping cart. Events belonging to some shopping cart must be processed in a sequential order, however they\n",
"are independent from events belonging to other shopping carts. Therefore, events belonging to distinct shopping carts\n",
"can be processed in parallel. Using `AsyncSeq.groupBy`, we can partition the stream into a fixed set of sub-streams \n",
"and then process the sub-streams in parallel using `AsyncSeq.mapAsyncParallel`:\n",
"\n",
"\n"]
          }
,
          {
           "cell_type": "code",
           "metadata": {},
            "execution_count": null, "outputs": [], 
           "source": ["stream\n",
"|\u003e AsyncSeq.groupBy (fun e -\u003e int e.entityId % 4)\n",
"|\u003e AsyncSeq.mapAsyncParallel (snd \u003e\u003e AsyncSeq.iterAsync action)\n",
"|\u003e AsyncSeq.iter ignore\n"]
          }
,
          {
           "cell_type": "markdown",
           "metadata": {},
           
           "source": ["`AsyncSeq.groupBy` partitions the input sequence into sub-sequences based on a key returned by a projection function. \n",
"The resulting sub-sequences emit elements when the source sequence emits an element corresponding to the key of the \n",
"sub-sequence. Elements of the resulting sequence are pairs of keys and sub-sequences, in this case `int * AsyncSeq\u003cEvent\u003e`. Since by definition, these sub-sequences are independent, they can be processed in parallel. In fact, the sub-sequences *must* be processed in parallel, because it isn\u0027t possible to complete the processing of a sub-sequence until all elements of the source sequence are exhausted.\n",
"\n",
"To continue improving the efficiency of our workflow, we can make use of batching. Specifically, we can read the incoming\n",
"events in batches and we can perform actions on entire batches of events.\n",
"\n",
"\n"]
          }
,
          {
           "cell_type": "code",
           "metadata": {},
            "execution_count": null, "outputs": [], 
           "source": ["let batchStream : AsyncSeq\u003cEvent[]\u003e =\n",
"  failwith \"undefined\"\n",
"\n",
"let batchAction (es:Event[]) : Async\u003cunit\u003e =\n",
"  failwith \"undefined\"\n"]
          }
,
          {
           "cell_type": "markdown",
           "metadata": {},
           
           "source": ["Ordering is still important. For example, the batch action could write events into a full-text search index. We would like the full-text search index to be sequentially consistent. As such, the events need to be applied in the order they were emitted. The following workflow has the desired properties:\n",
"\n",
"\n"]
          }
,
          {
           "cell_type": "code",
           "metadata": {},
            "execution_count": null, "outputs": [], 
           "source": ["batchStream\n",
"|\u003e AsyncSeq.concatSeq // flatten the sequence of event arrays\n",
"|\u003e AsyncSeq.groupBy (fun e -\u003e int e.entityId % 4) // partition into 4 groups\n",
"|\u003e AsyncSeq.mapAsyncParallel (snd \n",
"  \u003e\u003e AsyncSeq.bufferByCountAndTime 500 1000 // buffer sub-sequences\n",
"  \u003e\u003e AsyncSeq.iterAsync batchAction) // perform the batch operation\n",
"|\u003e AsyncSeq.iter ignore\n"]
          }
,
          {
           "cell_type": "markdown",
           "metadata": {},
           
           "source": ["The above workflow:\n",
"\n",
"1. Reads events in batches.\n",
"2. Flattens the batches.\n",
"3. Partitions the events into mutually exclusive sub-sequences.\n",
"4. Buffers elements of each sub-sequence by time and space.\n",
"5. Processes the sub-sequences in parallel, but individual sub-sequences sequentially.\n",
"\n",
"## Merge\n",
"\n",
"`AsyncSeq.merge` non-deterministically merges two async sequences into one. It is non-deterministic in the sense that the resulting sequence emits elements whenever *either* input sequence emits a value. Since it isn\u0027t always known which will emit a value first, if at all, the operation is non-deterministic. This operation is in contrast to `AsyncSeq.zip` which also takes two async sequences and returns a single async sequence, but as opposed to emitting an element when *either* input sequence produces a value, it emits an element when *both* sequences emit a value. This operation is also in contrast to `AsyncSeq.append` which concatenates two async sequences, emitting all element of one, followed by all elements of the another.\n",
"\n",
"### Example Execution\n",
"\n",
"An example execution can be depicted visually as follows:\n",
"\n",
"```\n",
"-----------------------------------------\n",
"| source1 | t0 |    | t1 |    |    | t2 |\n",
"| source2 |    | u0 |    |    | u1 |    |\n",
"| result  | t0 | u0 | t1 |    | u1 | t2 |\n",
"-----------------------------------------\n",
"```\n",
"\n",
"### Use Case\n",
"\n",
"Suppose you wish to perform an operation when either of two async sequences emits an element. One way to do this is two start consuming both async sequences in parallel. If we would like to perform only one operation at a time, we can use `AsyncSeq.merge` as follows:\n",
"\n"]
          }
,
          {
           "cell_type": "code",
           "metadata": {},
            "execution_count": null, "outputs": [], 
           "source": ["/// Represents an stream emitting elements on a specified interval.\n",
"let intervalMs (periodMs:int) = asyncSeq {\n",
"  yield DateTime.UtcNow\n",
"  while true do\n",
"    do! Async.Sleep periodMs\n",
"    yield DateTime.UtcNow }\n",
"\n",
"let either : AsyncSeq\u003cDateTime\u003e =\n",
"  AsyncSeq.merge (intervalMs 20) (intervalMs 30)\n"]
          }
,
          {
           "cell_type": "markdown",
           "metadata": {},
           
           "source": ["The sequence `either` emits an element every 20ms and every 30ms.\n",
"\n",
"## Combine Latest\n",
"\n",
"\n",
"`AsyncSeq.combineLatest` non-deterministically merges two async sequences much like `AsyncSeq.merge`, combining their elements using the specified `combine` function. The resulting async sequence will only contain elements if both of the source sequences produce at least one element. After combining the first elements the source sequences, this operation emits elements when either source sequence emits an element, passing the newly emitted element as one of the arguments to the `combine` function, the other being the previously emitted element of that type.\n",
"\n",
"### Example Execution\n",
"\n",
"An example execution can be depicted visually as follows:\n",
"\n",
"```\n",
"----------------------------------------\n",
"| source1 | a0 |    |    | a1 |   | a2 |\n",
"| source2 |    | b0 | b1 |    |   |    |\n",
"| result  |    | c0 | c1 | c2 |   | c3 |\n",
"----------------------------------------\n",
"\n",
"where\n",
"\n",
"c0 = f a0 b0\n",
"c1 = f a0 b1\n",
"c2 = f a1 b1\n",
"c3 = f a2 b1\n",
"```\n",
"\n",
"### Use Case\n",
"\n",
"Suppose we would like to trigger an operation whenever a change occurs. We can represent changes as an `AsyncSeq`. To gain intuition for this, consider the [Consul](https://www.consul.io/)\n",
"configuration management system. It stores configuration information in a tree-like structure. For this purpose of this discussion, it can be thought of as a key-value store\n",
"exposed via HTTP. In addition, `Consul` supports change notifications using HTTP long-polling - when an HTTP GET request is made to retrieve the value of a key, \n",
"if the request specified a modify-index, `Consul` won\u0027t respond to the request until a change has occurred *since* the modify-index. We can represent this operation using \n",
"the type `Key * ModifyIndex -\u003e Async\u003cValue * ModifyIndex\u003e`. Next, we can take this operation and turn it into an `AsyncSeq` of changes as follows:\n",
"\n"]
          }
,
          {
           "cell_type": "code",
           "metadata": {},
            "execution_count": null, "outputs": [], 
           "source": ["type Key = string\n",
"\n",
"type Value = string\n",
"\n",
"type ModifyIndex = int64\n",
"\n",
"let longPollKey (key:Key, mi:ModifyIndex) : Async\u003cValue * ModifyIndex\u003e =\n",
"  failwith \"undefined\"\n",
"\n",
"let changes (key:Key, mi:ModifyIndex) : AsyncSeq\u003cValue\u003e =\n",
"  AsyncSeq.unfoldAsync \n",
"    (fun (mi:ModifyIndex) -\u003e async {\n",
"      let! value,mi = longPollKey (key, mi)\n",
"      return Some (value,mi) })\n",
"    mi\n"]
          }
,
          {
           "cell_type": "markdown",
           "metadata": {},
           
           "source": ["The function `changes` produces an async sequence which emits elements whenever the value corresponding to the key changes. Suppose also that we would like to trigger an operation\n",
"whenever the key changes or based on a fixed interval. We can represent a fixed interval as an async sequence as follows:\n",
"\n",
"Putting it all together:\n",
"\n",
"\n"]
          }
,
          {
           "cell_type": "code",
           "metadata": {},
            "execution_count": null, "outputs": [], 
           "source": ["let changesOrInterval : AsyncSeq\u003cValue\u003e =\n",
"  AsyncSeq.combineLatestWith (fun v _ -\u003e v) (changes (\"myKey\", 0L)) (intervalMs (1000 * 60))\n"]
          }
,
          {
           "cell_type": "markdown",
           "metadata": {},
           
           "source": ["We can now consume this async sequence and use it to trigger downstream operations, such as updating the configuration of a running program, in flight.\n",
"\n",
"\n",
"## Distinct Until Changed\n",
"\n",
"`AsyncSeq.distinctUntilChanged` returns an async sequence which returns every element of the source sequence, skipping elements which equal its predecessor.\n",
"\n",
"## Example Execution\n",
"\n",
"An example execution can be visualized as follows:\n",
"\n",
"```\n",
"-----------------------------------\n",
"| source  | a | a | b | b | b | a |\n",
"| result  | a |   | b |   |   | a |\n",
"-----------------------------------\n",
"```\n",
"\n",
"### Use Case\n",
"\n",
"Suppose you\u0027re polling a resource which returns status information of a background job.\n",
"\n",
"\n"]
          }
,
          {
           "cell_type": "code",
           "metadata": {},
            "execution_count": null, "outputs": [], 
           "source": ["type Status = {\n",
"  completed : int\n",
"  finished : bool\n",
"  result : string\n",
"}\n",
"\n",
"/// Gets the status of a job.\n",
"let status : Async\u003cStatus\u003e =\n",
"  failwith \"\"\n",
"\n",
"let statuses : AsyncSeq\u003cStatus\u003e =\n",
"  asyncSeq {\n",
"    let! s = status\n",
"    while true do\n",
"      do! Async.Sleep 1000\n",
"      let! s = status\n",
"      yield s }\n"]
          }
,
          {
           "cell_type": "markdown",
           "metadata": {},
           
           "source": ["The async sequence `statuses` will return a status every second. It will return a status regardless of whether the status changed. Assuming the status changes monotonically, we can use `AsyncSeq.distinctUntilChanged` to transform `statuses` into an async sequence of distinct statuses:\n",
"\n",
"\n"]
          }
,
          {
           "cell_type": "code",
           "metadata": {},
            "execution_count": null, "outputs": [], 
           "source": ["let distinctStatuses : AsyncSeq\u003cStatus\u003e =\n",
"  statuses |\u003e AsyncSeq.distinctUntilChanged\n"]
          }
,
          {
           "cell_type": "markdown",
           "metadata": {},
           
           "source": ["Finally, we can create a workflow which prints the status every time a change is detected and terminates when the underlying job reaches the `finished` state:\n",
"\n",
"\n"]
          }
,
          {
           "cell_type": "code",
           "metadata": {},
            "execution_count": null, "outputs": [], 
           "source": ["let result : Async\u003cstring\u003e =\n",
"  distinctStatuses\n",
"  |\u003e AsyncSeq.pick (fun st -\u003e \n",
"    printfn \"status=%A\" st\n",
"    if st.finished then Some st.result\n",
"    else None)\n"]
          }
,
          {
           "cell_type": "markdown",
           "metadata": {},
           
           "source": ["## Zip\n",
"\n",
"\n",
"`AsyncSeq.zip : AsyncSeq\u003c\u0027a\u003e -\u003e AsyncSeq\u003c\u0027b\u003e -\u003e AsyncSeq\u003c\u0027a * \u0027b\u003e` takes a pair of sequences and combines them into a sequence of pairs element wise - the first element of one sequence is paired with the first element of the other, and so on. It can be used to pair sequences of related elements into a single sequence. It can also be used to combine a sequence of elements with a sequence of effects. \n",
"\n",
"### Example Execution\n",
"\n",
"An example execution can be visually depicted as follows:\n",
"\n",
"```\n",
"---------------------------------------------\n",
"| source1  |    a1    |    a2    |          |\n",
"| source2  |    b1    |    b2    |    b3    |\n",
"| result   |  a1 * b1 |  a2 * b2 |          | \n",
"---------------------------------------------\n",
"``` \n",
"\n",
"Note that the resulting sequence terminates when either input sequence terminates. \n",
"\n",
"### Use Case\n",
"\n",
"Suppose that we have an async sequence of events consumed from a message bus. We would like to process this sequence but we want to ensure that we\u0027re not processing to fast. We can pair the sequence of events with a sequence of durations corresponding to the minimum consumption time. We can do this as follows:\n",
"\n",
"\n"]
          }
,
          {
           "cell_type": "code",
           "metadata": {},
            "execution_count": null, "outputs": [], 
           "source": ["let events : AsyncSeq\u003cEvent\u003e =\n",
"  failwith \"TODO\"\n",
"\n",
"let eventsAtLeastOneSec =\n",
"  AsyncSeq.zipWith \n",
"    (fun a _ -\u003e a) \n",
"    events \n",
"    (AsyncSeq.replicateInfiniteAsync (Async.Sleep 1000))\n"]
          }
,
          {
           "cell_type": "markdown",
           "metadata": {},
           
           "source": ["The resulting async sequence `eventsAtLeastOneSec` will emit an element at-most every second. Note that the input sequence of timeouts is infinite - this is to allow the other sequence to have any length since `AsyncSeq.zipWith` will terminate when either input sequence terminates.\n",
"\n",
"## Buffer by Time and Count\n",
"\n",
"`AsyncSeq.bufferByTimeAndCount` consumes the input sequence until a specified number of elements are consumed or a timeout expires at which point the resulting sequence emits the buffered of elements, unless no elements have been buffered. It is similar to `AsyncSeq.bufferByCount` but allows a buffer to be emitted base on a timeout in addition to buffer size. Both are useful for batching inputs before performing an operation. `AsyncSeq.bufferByTimeAndCount` allows an async workflow to proceed even if there are no inputs received during a certain time period.\n",
"\n",
"### Example Execution\n",
"\n",
"An example execution can be visually depicted as follows:\n",
"\n",
"```\n",
"-------------------------------------------------------\n",
"| source   |  a1 | a2 | a3         | a4      |        |\n",
"| result   |     |    | [a1,a2,a3] |         |  [a4]  |\n",
"-------------------------------------------------------\n",
"```\n",
"The last event `a4` is emitted after a timeout.\n",
"\n",
"### Use Case\n",
"\n",
"Suppose we\u0027re writing a service which consumes a stream of events and indexes them into full-text search index. We can index each event one by one, however we get a performance improvement if we buffer events into small batches. We can buffer into fixed size batches using `AsyncSeq.bufferByCount`. However, the source event stream may stop emitting events half way through a batch which would leave those events in the buffer until more events arrive. `AsyncSeq.bufferByTimeAndCount` allows the async workflow to make progress by imposing a bound on how long a non-empty but incomplete buffer can wait more additional items.\n",
"\n",
"\n"]
          }
,
          {
           "cell_type": "code",
           "metadata": {},
            "execution_count": null, "outputs": [], 
           "source": ["let individualEvents : AsyncSeq\u003cEvent\u003e =\n",
"  failwith \"\"\n",
"\n",
"let bufferSize = 100\n",
"let bufferTimeout = 1000\n",
"\n",
"let bufferedEvents : AsyncSeq\u003cEvent[]\u003e =\n",
"  events |\u003e AsyncSeq.bufferByCountAndTime bufferSize bufferTimeout   \n"]
          }],
            "metadata": {
            "kernelspec": {"display_name": ".NET (F#)", "language": "F#", "name": ".net-fsharp"},
            "langauge_info": {
        "file_extension": ".fs",
        "mimetype": "text/x-fsharp",
        "name": "C#",
        "pygments_lexer": "fsharp",
        "version": "4.5"
        }
        },
            "nbformat": 4,
            "nbformat_minor": 1
        }
        

